{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cb4c94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kihyvr/miniconda3/envs/llmenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from utils_emotiontraining import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bcfc88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModel.from_pretrained(\"distilroberta-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilroberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca87985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# if cannot find path to dataset, use this:\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"augmented_emotion_dataset\"):\n",
    "    emotion_dataset = load_dataset(\"google-research-datasets/go_emotions\", \"simplified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa5c1b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a larger subset of examples for better training\n",
    "small_train_dataset = emotion_dataset['train'].select(range(10000))\n",
    "small_test_dataset = emotion_dataset['test'].select(range(1000))\n",
    "\n",
    "# Create a new small dataset with the reduced splits\n",
    "small_emotion_dataset = {\n",
    "    'train': small_train_dataset,\n",
    "    'test': small_test_dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efe6e794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of emotions dataset:\n",
      "{'text': \"My favourite food is anything I didn't have to cook myself.\", 'labels': [27], 'id': 'eebbqej'}\n",
      "Number of labels: 28\n"
     ]
    }
   ],
   "source": [
    "emotions_id2label = {\n",
    "    0: 'admiration',\n",
    "    1: 'amusement',\n",
    "    2: 'anger',\n",
    "    3: 'annoyance',\n",
    "    4: 'approval',\n",
    "    5: 'caring',\n",
    "    6: 'confusion',\n",
    "    7: 'curiosity',\n",
    "    8: 'desire',\n",
    "    9: 'disappointment',\n",
    "    10: 'disapproval',\n",
    "    11: 'disgust',\n",
    "    12: 'embarrassment',\n",
    "    13: 'excitement',\n",
    "    14: 'fear',\n",
    "    15: 'gratitude',\n",
    "    16: 'grief',\n",
    "    17: 'joy',\n",
    "    18: 'love',\n",
    "    19: 'nervousness',\n",
    "    20: 'optimism',\n",
    "    21: 'pride',\n",
    "    22: 'realization',\n",
    "    23: 'relief',\n",
    "    24: 'remorse',\n",
    "    25: 'sadness',\n",
    "    26: 'surprise',\n",
    "    27: 'neutral'  # Last entry (no comma)\n",
    "}\n",
    "\n",
    "emotions_label2id = {v: k for k, v in emotions_id2label.items()}\n",
    "\n",
    "# Print dataset info to verify we understand what we're working with\n",
    "print(\"Sample of emotions dataset:\")\n",
    "print(small_emotion_dataset[\"train\"][0])\n",
    "print(f\"Number of labels: {len(emotions_id2label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c515f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of augmented training data:\n",
      "Original: My favourite food is anything I didn't have to cook myself.\n",
      "Augmented: My favourite food is anything I didn't have to cook myself.\n",
      "Labels: [27]\n",
      "\n",
      "Original: Now if he does off himself, everyone will think hes having a laugh screwing with people instead of actually dead\n",
      "Augmented: Now if he does off himself, everyone will think hes having a laugh screwing with people instead of actually dead\n",
      "Labels: [27]\n",
      "\n",
      "Original: WHY THE FUCK IS BAYLESS ISOING\n",
      "Augmented: WHY THE FUCK IS BAYLESS ISOING\n",
      "Labels: [2]\n",
      "\n",
      "Original: To make her feel threatened\n",
      "Augmented: To make her feel threatened\n",
      "Labels: [14]\n",
      "\n",
      "Original: Dirty Southern Wankers\n",
      "Augmented: Dirty Southern Wankers\n",
      "Labels: [3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell source for ID: 4c515f62 (Simplified Logic)\n",
    "MINORITY_THRESHOLD_PERCENT = 1.0\n",
    "from collections import Counter\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import re\n",
    "\n",
    "print(\"Sample of augmented training data:\")\n",
    "num_samples_to_show = min(5, len(small_train_dataset))\n",
    "if num_samples_to_show > 0:\n",
    "    for i in range(num_samples_to_show):\n",
    "        original_text_display = small_train_dataset[i].get('text', 'N/A')\n",
    "        augmented_text_display = small_train_dataset[i].get('text', 'N/A')\n",
    "        labels_display = small_train_dataset[i].get('labels', 'N/A')\n",
    "        print(f\"Original: {original_text_display}\")\n",
    "        print(f\"Augmented: {augmented_text_display}\")\n",
    "        print(f\"Labels: {labels_display}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"Augmented dataset appears empty or has fewer than 5 samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d906f8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 20458.51 examples/s]\n",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 41419.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'labels', 'id', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 10000\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True, return_tensors='tf')\n",
    "\n",
    "# Tokenize the small dataset\n",
    "small_emotions_encoded = {}\n",
    "small_emotions_encoded['train'] = small_emotion_dataset['train'].map(tokenize, batched=True, batch_size=None)\n",
    "small_emotions_encoded['test'] = small_emotion_dataset['test'].map(tokenize, batched=True, batch_size=None)\n",
    "\n",
    "print(small_emotions_encoded['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f6d48f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 19836.48 examples/s]\n",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 20911.71 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing existing columns: ['labels']\n",
      "Renaming 'multi_hot_labels' to 'labels'\n",
      "Calculating sample weights...\n",
      "Sample weights calculated.\n",
      "Setting dataset format to TensorFlow\n",
      "Creating tf.data.Dataset objects with sample weights...\n",
      "Datasets created successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "\n",
    "NUM_CLASSES = 28  # Define the number of classes (matches emotions_id2label)\n",
    "\n",
    "def create_multi_hot_labels(example):\n",
    "    \"\"\"Convert the list of labels into a multi-hot encoded vector.\"\"\"\n",
    "    multi_hot_label = np.zeros(NUM_CLASSES, dtype=np.float32)\n",
    "    if 'labels' in example and isinstance(example['labels'], list) and len(example['labels']) > 0:\n",
    "        for label_id in example['labels']:\n",
    "            if isinstance(label_id, int) and 0 <= label_id < NUM_CLASSES:\n",
    "                multi_hot_label[label_id] = 1.0\n",
    "    example['multi_hot_labels'] = multi_hot_label\n",
    "    return example\n",
    "\n",
    "# Apply the conversion to add the new multi-hot label column\n",
    "small_emotions_encoded['train'] = small_emotions_encoded['train'].map(create_multi_hot_labels)\n",
    "small_emotions_encoded['test'] = small_emotions_encoded['test'].map(create_multi_hot_labels)\n",
    "\n",
    "# Remove the original 'labels' column and any leftover 'label_int'\n",
    "columns_to_remove = [col for col in ['label_int', 'labels'] if col in small_emotions_encoded['train'].features]\n",
    "if columns_to_remove:\n",
    "    print(f\"Removing existing columns: {columns_to_remove}\")\n",
    "    small_emotions_encoded['train'] = small_emotions_encoded['train'].remove_columns(columns_to_remove)\n",
    "    small_emotions_encoded['test'] = small_emotions_encoded['test'].remove_columns(columns_to_remove)\n",
    "\n",
    "# Rename the new column 'multi_hot_labels' to 'labels'\n",
    "if 'multi_hot_labels' in small_emotions_encoded['train'].features:\n",
    "    print(\"Renaming 'multi_hot_labels' to 'labels'\")\n",
    "    small_emotions_encoded['train'] = small_emotions_encoded['train'].rename_column('multi_hot_labels', 'labels')\n",
    "if 'multi_hot_labels' in small_emotions_encoded['test'].features:\n",
    "    small_emotions_encoded['test'] = small_emotions_encoded['test'].rename_column('multi_hot_labels', 'labels')\n",
    "\n",
    "# --- Add Sample Weight Calculation ---\n",
    "print(\"Calculating sample weights...\")\n",
    "# Get all multi-hot labels from the training set as a NumPy array\n",
    "train_labels_np = np.array(small_emotions_encoded['train']['labels'])\n",
    "# Count frequency of each label (column-wise sum)\n",
    "label_counts = np.sum(train_labels_np, axis=0)\n",
    "total_samples = len(train_labels_np)\n",
    "\n",
    "# Calculate weight for each class (inverse frequency, smoothed)\n",
    "class_weights_calc = {}\n",
    "for i in range(NUM_CLASSES):\n",
    "    # Avoid division by zero for labels that might not appear in the subset\n",
    "    count = label_counts[i] if label_counts[i] > 0 else 1\n",
    "    class_weights_calc[i] = total_samples / (NUM_CLASSES * count)\n",
    "\n",
    "# Calculate weight for each sample: max weight of its positive labels\n",
    "sample_weights_np = np.zeros(total_samples, dtype=np.float32)\n",
    "for i in range(total_samples):\n",
    "    sample_label_indices = np.where(train_labels_np[i] == 1.0)[0]\n",
    "    if len(sample_label_indices) > 0:\n",
    "        sample_weights_np[i] = max(class_weights_calc[idx] for idx in sample_label_indices)\n",
    "    else:\n",
    "        # Assign a default weight (e.g., 1.0 or average) for samples with no positive labels\n",
    "        sample_weights_np[i] = 1.0\n",
    "print(\"Sample weights calculated.\")\n",
    "# --- End Sample Weight Calculation ---\n",
    "\n",
    "\n",
    "# Set format to tensorflow\n",
    "feature_cols = [\"input_ids\", \"attention_mask\"]\n",
    "label_col = \"labels\"\n",
    "cols_to_set_format = feature_cols + [label_col]\n",
    "\n",
    "actual_train_cols = list(small_emotions_encoded['train'].features)\n",
    "actual_test_cols = list(small_emotions_encoded['test'].features)\n",
    "final_train_cols = [col for col in cols_to_set_format if col in actual_train_cols]\n",
    "final_test_cols = [col for col in cols_to_set_format if col in actual_test_cols]\n",
    "\n",
    "if all(col in final_train_cols for col in cols_to_set_format) and \\\n",
    "   all(col in final_test_cols for col in cols_to_set_format):\n",
    "    print(\"Setting dataset format to TensorFlow\")\n",
    "    # Don't set format yet, extract numpy arrays first, then create dataset\n",
    "else:\n",
    "     raise ValueError(f\"Error: Could not find all necessary columns. Train has: {actual_train_cols}, Test has: {actual_test_cols}. Needed: {cols_to_set_format}\")\n",
    "\n",
    "\n",
    "# Extract features and labels as numpy arrays before creating dataset\n",
    "train_features_np = {col: np.array(small_emotions_encoded['train'][col]) for col in feature_cols}\n",
    "train_labels_np = np.array(small_emotions_encoded['train']['labels']) # Already have this from weight calc\n",
    "\n",
    "test_features_np = {col: np.array(small_emotions_encoded['test'][col]) for col in feature_cols}\n",
    "test_labels_np = np.array(small_emotions_encoded['test']['labels'])\n",
    "\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "BATCH_SIZE = 32 # Keep batch size reasonable\n",
    "\n",
    "print(\"Creating tf.data.Dataset objects with sample weights...\")\n",
    "# Modify train_dataset to yield (features, labels, sample_weights)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_features_np, train_labels_np, sample_weights_np)\n",
    ")\n",
    "train_dataset = train_dataset.shuffle(len(sample_weights_np)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE) # Add prefetch\n",
    "\n",
    "# Test dataset remains (features, labels)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (test_features_np, test_labels_np)\n",
    ")\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE) # Add prefetch\n",
    "print(\"Datasets created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e067bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTForClassification(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, bert_model, num_classes):\n",
    "        super().__init__()\n",
    "        self.bert = bert_model\n",
    "        # Change activation to 'sigmoid' for multi-label classification\n",
    "        self.fc = tf.keras.layers.Dense(num_classes, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Make sure we handle the case when inputs is a dictionary\n",
    "        outputs = self.bert(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            return_dict=True\n",
    "        )\n",
    "        pooled_output = outputs.pooler_output\n",
    "        return self.fc(pooled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce5b9f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define NUM_CLASSES if not defined globally earlier\n",
    "try:\n",
    "    NUM_CLASSES\n",
    "except NameError:\n",
    "    NUM_CLASSES = 28 # Set default if run out of order\n",
    "\n",
    "# Create a shared emotion prediction function for multi-label output\n",
    "def predict_emotion(text, model, threshold=0.5):\n",
    "    \"\"\"Predict multiple emotions for a given text using the provided model and threshold\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors='tf', padding=True, truncation=True)\n",
    "    predictions = model(inputs) # Shape: (1, NUM_CLASSES)\n",
    "\n",
    "    # --- Add this line temporarily ---\n",
    "    # print(f\"Raw probabilities for '{text}': {predictions[0].numpy()}\")\n",
    "    # --- End of added line ---\n",
    "\n",
    "    predicted_labels_indices = tf.where(predictions[0] > threshold).numpy().flatten()\n",
    "    predicted_emotions = []\n",
    "    confidences = []\n",
    "    if len(predicted_labels_indices) > 0:\n",
    "        for index in predicted_labels_indices:\n",
    "            predicted_emotions.append(emotions_id2label[index])\n",
    "            confidences.append(float(predictions[0][index]))\n",
    "    else:\n",
    "        # Optional: If no label passes threshold, predict the highest one or 'neutral'\n",
    "        highest_prob_index = tf.argmax(predictions, axis=1).numpy()[0]\n",
    "        predicted_emotions.append(emotions_id2label[highest_prob_index])\n",
    "        confidences.append(float(predictions[0][highest_prob_index]))\n",
    "\n",
    "\n",
    "    return {\n",
    "        'text': text,\n",
    "        'emotions': predicted_emotions,\n",
    "        'confidences': confidences\n",
    "    }\n",
    "\n",
    "# Define test texts to use for both untrained and trained models\n",
    "test_texts = [\n",
    "    \"I'm so happy today!\",\n",
    "    \"This makes me really angry.\",\n",
    "    \"I'm feeling very sad and disappointed.\",\n",
    "    \"That's really interesting, tell me more.\",\n",
    "    \"I am both excited and nervous about the presentation.\", # Example with multiple emotions\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b76f343",
   "metadata": {},
   "source": [
    "## Analyze Test Texts with Untrained Model\n",
    "\n",
    "Let's first create and test our model before training to establish a baseline. This will show how the model performs with random weights, which we can compare to the fine-tuned model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87469b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions with UNTRAINED model (random weights - multi-label):\n",
      "-------------------------------------------------------------\n",
      "Text: I'm so happy today!\n",
      "Predicted emotions: ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
      "Confidences: [('admiration', 0.7032246589660645), ('amusement', 0.4195410907268524), ('anger', 0.4252801537513733), ('annoyance', 0.5530133247375488), ('approval', 0.48919641971588135), ('caring', 0.5244767069816589), ('confusion', 0.4554974436759949), ('curiosity', 0.5426892042160034), ('desire', 0.4391227960586548), ('disappointment', 0.6152594685554504), ('disapproval', 0.48842307925224304), ('disgust', 0.4899848699569702), ('embarrassment', 0.4912385940551758), ('excitement', 0.48592326045036316), ('fear', 0.522710919380188), ('gratitude', 0.5250958204269409), ('grief', 0.4356943666934967), ('joy', 0.3985837697982788), ('love', 0.7102387547492981), ('nervousness', 0.47809284925460815), ('optimism', 0.5140818357467651), ('pride', 0.5481431484222412), ('realization', 0.5857362747192383), ('relief', 0.39186549186706543), ('remorse', 0.6208188533782959), ('sadness', 0.5507597923278809), ('surprise', 0.5064029097557068), ('neutral', 0.5614708662033081)]\n",
      "\n",
      "Text: This makes me really angry.\n",
      "Predicted emotions: ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
      "Confidences: [('admiration', 0.7028192281723022), ('amusement', 0.4242829382419586), ('anger', 0.4254419207572937), ('annoyance', 0.5569519400596619), ('approval', 0.4870016574859619), ('caring', 0.5278145670890808), ('confusion', 0.45779654383659363), ('curiosity', 0.5354043841362), ('desire', 0.43900027871131897), ('disappointment', 0.6187173128128052), ('disapproval', 0.48852694034576416), ('disgust', 0.4907631278038025), ('embarrassment', 0.4938550591468811), ('excitement', 0.4896910488605499), ('fear', 0.5228626728057861), ('gratitude', 0.5235705971717834), ('grief', 0.43281662464141846), ('joy', 0.38940417766571045), ('love', 0.7177740335464478), ('nervousness', 0.47657155990600586), ('optimism', 0.5092514157295227), ('pride', 0.5519648790359497), ('realization', 0.5871737003326416), ('relief', 0.3913857340812683), ('remorse', 0.6196308135986328), ('sadness', 0.5403643250465393), ('surprise', 0.5138423442840576), ('neutral', 0.5591751933097839)]\n",
      "\n",
      "Text: I'm feeling very sad and disappointed.\n",
      "Predicted emotions: ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
      "Confidences: [('admiration', 0.7030884027481079), ('amusement', 0.4277326464653015), ('anger', 0.4229021668434143), ('annoyance', 0.5562072992324829), ('approval', 0.4909275472164154), ('caring', 0.5287786722183228), ('confusion', 0.4562658369541168), ('curiosity', 0.5294277667999268), ('desire', 0.4385359287261963), ('disappointment', 0.618497908115387), ('disapproval', 0.4886763095855713), ('disgust', 0.49083536863327026), ('embarrassment', 0.4911302328109741), ('excitement', 0.4885542094707489), ('fear', 0.5187214016914368), ('gratitude', 0.5220310688018799), ('grief', 0.4357256591320038), ('joy', 0.39122846722602844), ('love', 0.7164095044136047), ('nervousness', 0.47844013571739197), ('optimism', 0.5082816481590271), ('pride', 0.5490060448646545), ('realization', 0.590034008026123), ('relief', 0.3896436393260956), ('remorse', 0.6208407878875732), ('sadness', 0.5419122576713562), ('surprise', 0.5156291723251343), ('neutral', 0.5623183846473694)]\n",
      "\n",
      "Text: That's really interesting, tell me more.\n",
      "Predicted emotions: ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
      "Confidences: [('admiration', 0.7008689045906067), ('amusement', 0.4202853739261627), ('anger', 0.4220535457134247), ('annoyance', 0.5578821301460266), ('approval', 0.4832823872566223), ('caring', 0.5275758504867554), ('confusion', 0.46161240339279175), ('curiosity', 0.5327853560447693), ('desire', 0.43602386116981506), ('disappointment', 0.6194554567337036), ('disapproval', 0.48620301485061646), ('disgust', 0.4960562288761139), ('embarrassment', 0.49059709906578064), ('excitement', 0.47788873314857483), ('fear', 0.5229364633560181), ('gratitude', 0.5246045589447021), ('grief', 0.4305754601955414), ('joy', 0.38936060667037964), ('love', 0.7164784073829651), ('nervousness', 0.4764709770679474), ('optimism', 0.5035423040390015), ('pride', 0.5517334938049316), ('realization', 0.5870863795280457), ('relief', 0.3901294469833374), ('remorse', 0.6213812232017517), ('sadness', 0.5448322296142578), ('surprise', 0.5114099383354187), ('neutral', 0.5585809350013733)]\n",
      "\n",
      "Text: I am both excited and nervous about the presentation.\n",
      "Predicted emotions: ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
      "Confidences: [('admiration', 0.702053427696228), ('amusement', 0.4233940541744232), ('anger', 0.42518946528434753), ('annoyance', 0.5564730763435364), ('approval', 0.4880208969116211), ('caring', 0.5323611497879028), ('confusion', 0.45854681730270386), ('curiosity', 0.5344566702842712), ('desire', 0.44037869572639465), ('disappointment', 0.6204853057861328), ('disapproval', 0.49221891164779663), ('disgust', 0.492289662361145), ('embarrassment', 0.4962979555130005), ('excitement', 0.48356905579566956), ('fear', 0.5193057656288147), ('gratitude', 0.5279477834701538), ('grief', 0.43450498580932617), ('joy', 0.3918609917163849), ('love', 0.713541567325592), ('nervousness', 0.47925493121147156), ('optimism', 0.5056250691413879), ('pride', 0.5516594052314758), ('realization', 0.5866338014602661), ('relief', 0.392475426197052), ('remorse', 0.6188468337059021), ('sadness', 0.5469121932983398), ('surprise', 0.5134500861167908), ('neutral', 0.5633672475814819)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an untrained model for baseline comparison\n",
    "# Ensure the base model 'model' is loaded correctly from cell 2\n",
    "untrained_classifier = BERTForClassification(model, num_classes=NUM_CLASSES)\n",
    "\n",
    "# Compile the model for multi-label classification\n",
    "untrained_classifier.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=2e-5),\n",
    "    # Use BinaryCrossentropy for multi-label with sigmoid activation\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    # Use BinaryAccuracy for multi-label evaluation\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "print(\"Predictions with UNTRAINED model (random weights - multi-label):\")\n",
    "print(\"-------------------------------------------------------------\")\n",
    "\n",
    "# Get predictions from untrained model using our updated shared function\n",
    "for text in test_texts:\n",
    "    result = predict_emotion(text, untrained_classifier, threshold=0.1) # Lower threshold for untrained might show more random outputs\n",
    "    print(f\"Text: {result['text']}\")\n",
    "    print(f\"Predicted emotions: {result['emotions']}\")\n",
    "    # Zip confidences with emotions for clarity\n",
    "    emotion_confidence_pairs = list(zip(result['emotions'], result['confidences']))\n",
    "    print(f\"Confidences: {emotion_confidence_pairs}\")\n",
    "    # print(f\"Confidences: {[f'{c:.4f}' for c in result['confidences']]}\")\n",
    "    print()\n",
    "\n",
    "# Evaluating accuracy on the test set for an untrained multi-label model isn't very informative\n",
    "# untrained_loss, untrained_accuracy = untrained_classifier.evaluate(test_dataset, verbose=0)\n",
    "# print(f\"Untrained model test accuracy (BinaryAccuracy): {untrained_accuracy:.4f}\")\n",
    "# Random baseline for BinaryAccuracy depends on label distribution, harder to interpret than single-label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d127d7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model with AUC, Precision, Recall...\n",
      "Model compiled.\n"
     ]
    }
   ],
   "source": [
    "# --- Suggested Change for Cell ID: d127d7b4 ---\n",
    "\n",
    "# Update num_classes if not already defined\n",
    "try:\n",
    "    NUM_CLASSES\n",
    "except NameError:\n",
    "    NUM_CLASSES = 28\n",
    "\n",
    "# Define the model - ensure 'model' (the base BERT model) is loaded\n",
    "classifier = BERTForClassification(model, num_classes=NUM_CLASSES)\n",
    "\n",
    "# Compile the model for multi-label classification with more metrics\n",
    "print(\"Compiling model with AUC, Precision, Recall...\")\n",
    "classifier.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=2e-5), # Consider trying AdamW later\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(), # Correct loss for multi-label sigmoid\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.AUC(multi_label=True, name='auc'), # Good overall multi-label metric\n",
    "        tf.keras.metrics.Precision(name='precision'), # How many selected items are relevant?\n",
    "        tf.keras.metrics.Recall(name='recall') # How many relevant items are selected?\n",
    "        ]\n",
    ")\n",
    "print(\"Model compiled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9df6074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting multi-label model training with sample weights...\n",
      "313/313 [==============================] - 1597s 5s/step - loss: 0.0039 - accuracy: 1.0000 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0019 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Training finished.\n",
      "Evaluating model on test set...\n",
      "32/32 [==============================] - 12s 379ms/step - loss: 0.0019 - accuracy: 1.0000 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "\n",
      "Test Set Evaluation Results:\n",
      "- loss: 0.0019\n",
      "- accuracy: 1.0000\n",
      "- auc: 0.0000\n",
      "- precision: 0.0000\n",
      "- recall: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# --- Suggested Change for Cell ID: e9df6074 ---\n",
    "\n",
    "# Train the model\n",
    "# Sample weights are now included in train_dataset, so no class_weight argument needed\n",
    "print(\"Starting multi-label model training with sample weights...\")\n",
    "# callbacks = [\n",
    "#     tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=3, mode='max', restore_best_weights=True),\n",
    "#     tf.keras.callbacks.ModelCheckpoint('best_emotion_model.keras', save_best_only=True, monitor='val_auc', mode='max')\n",
    "# ]\n",
    "\n",
    "history = classifier.fit(\n",
    "    train_dataset,\n",
    "    epochs=1,  # Adjust epochs as needed, more data might require more/fewer epochs\n",
    "    validation_data=test_dataset\n",
    "    # callbacks=callbacks # Uncomment to use callbacks\n",
    ")\n",
    "print(\"Training finished.\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(\"Evaluating model on test set...\")\n",
    "results = classifier.evaluate(test_dataset, verbose=1) # Use verbose=1 to see progress\n",
    "\n",
    "# Print evaluation results dynamically based on compiled metrics\n",
    "print(\"\\nTest Set Evaluation Results:\")\n",
    "for name, value in zip(classifier.metrics_names, results):\n",
    "    print(f\"- {name}: {value:.4f}\")\n",
    "\n",
    "# test_loss = results[classifier.metrics_names.index('loss')]\n",
    "# test_auc = results[classifier.metrics_names.index('auc')]\n",
    "# print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "# print(f\"Test AUC: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f61dbca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions with TRAINED multi-label model:\n",
      "----------------------------------------\n",
      "Text: I'm so happy today!\n",
      "Predicted emotions: ['nervousness']\n",
      "Confidences: [('nervousness', 0.002956303535029292)]\n",
      "\n",
      "Text: This makes me really angry.\n",
      "Predicted emotions: ['nervousness']\n",
      "Confidences: [('nervousness', 0.002934002550318837)]\n",
      "\n",
      "Text: I'm feeling very sad and disappointed.\n",
      "Predicted emotions: ['nervousness']\n",
      "Confidences: [('nervousness', 0.0029893810860812664)]\n",
      "\n",
      "Text: That's really interesting, tell me more.\n",
      "Predicted emotions: ['nervousness']\n",
      "Confidences: [('nervousness', 0.0029663715977221727)]\n",
      "\n",
      "Text: I am both excited and nervous about the presentation.\n",
      "Predicted emotions: ['nervousness']\n",
      "Confidences: [('nervousness', 0.0029224834870547056)]\n",
      "\n",
      "Text: My hands were shaking as I opened the letter, unsure what to expect.\n",
      "Predicted emotions: ['nervousness']\n",
      "Confidences: [('nervousness', 0.002900628373026848)]\n",
      "\n",
      "Text: After the argument, the silence in the car was deafening and heavy.\n",
      "Predicted emotions: ['nervousness']\n",
      "Confidences: [('nervousness', 0.00290290336124599)]\n",
      "\n",
      "Text: Watching the sunset reminded me of our last trip together - a bittersweet memory.\n",
      "Predicted emotions: ['nervousness']\n",
      "Confidences: [('nervousness', 0.00291572418063879)]\n",
      "\n",
      "Text: I'm relieved the project is finally over, but also a bit anxious about what comes next.\n",
      "Predicted emotions: ['nervousness']\n",
      "Confidences: [('nervousness', 0.0029401357751339674)]\n",
      "\n",
      "Text: Oh great, another 'urgent' all-hands meeting scheduled for 5 PM on a Friday. Just perfect.\n",
      "Predicted emotions: ['nervousness']\n",
      "Confidences: [('nervousness', 0.0028790975920856)]\n",
      "\n",
      "Text: Getting a flat tire miles from anywhere on the way to the most important interview of my life was exactly the kind of luck I needed.\n",
      "Predicted emotions: ['nervousness']\n",
      "Confidences: [('nervousness', 0.0028822075109928846)]\n",
      "\n",
      "Text: He delivered the bad news with a completely straight face, leaving us all reeling.\n",
      "Predicted emotions: ['nervousness']\n",
      "Confidences: [('nervousness', 0.0028752381913363934)]\n",
      "\n",
      "Text: Well, that certainly was an experience I won't forget anytime soon.\n",
      "Predicted emotions: ['nervousness']\n",
      "Confidences: [('nervousness', 0.00291824690066278)]\n",
      "\n",
      "Text: I wouldn't say I'm *thrilled* about the sudden change in plans, but I suppose I can adapt if necessary.\n",
      "Predicted emotions: ['nervousness']\n",
      "Confidences: [('nervousness', 0.0029421839863061905)]\n",
      "\n",
      "Text: Despite the initial burst of optimism, realizing the sheer amount of unexpected work ahead filled me with a quiet sense of dread.\n",
      "Predicted emotions: ['nervousness']\n",
      "Confidences: [('nervousness', 0.002883265959098935)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions with TRAINED multi-label model:\")\n",
    "print(\"----------------------------------------\")\n",
    "\n",
    "# Use the updated shared function with the trained model\n",
    "prediction_threshold = 0.1 # Adjust threshold as needed based on validation performance\n",
    "\n",
    "test_texts = TEST_TEXTS\n",
    "for text in test_texts:\n",
    "    result = predict_emotion(text, classifier, threshold=prediction_threshold)\n",
    "    print(f\"Text: {result['text']}\")\n",
    "    print(f\"Predicted emotions: {result['emotions']}\")\n",
    "    # Zip confidences with emotions for clarity\n",
    "    emotion_confidence_pairs = list(zip(result['emotions'], result['confidences']))\n",
    "    print(f\"Confidences: {emotion_confidence_pairs}\")\n",
    "    # print(f\"Confidences: {[f'{c:.4f}' for c in result['confidences']]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d42308a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'joy', 'score': 0.9998683929443359}, {'label': 'anger', 'score': 0.9998956918716431}, {'label': 'sadness', 'score': 0.9999432563781738}, {'label': 'neutral', 'score': 0.7713387608528137}, {'label': 'fear', 'score': 0.9935625791549683}, {'label': 'fear', 'score': 0.9996892213821411}, {'label': 'anger', 'score': 0.9703493714332581}, {'label': 'joy', 'score': 0.9454078674316406}, {'label': 'joy', 'score': 0.6393844485282898}, {'label': 'neutral', 'score': 0.7897074222564697}, {'label': 'sadness', 'score': 0.9980188608169556}, {'label': 'fear', 'score': 0.5129643082618713}, {'label': 'neutral', 'score': 0.9996825456619263}, {'label': 'joy', 'score': 0.9929666519165039}, {'label': 'fear', 'score': 0.9995587468147278}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model = 'borisn70/bert-43-multilabel-emotion-detection'\n",
    "tokenizer = 'borisn70/bert-43-multilabel-emotion-detection'\n",
    "\n",
    "# Create a pipeline for sentiment analysis\n",
    "nlp = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)\n",
    "\n",
    "testTexts = TEST_TEXTS\n",
    "result = nlp(testTexts)\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
