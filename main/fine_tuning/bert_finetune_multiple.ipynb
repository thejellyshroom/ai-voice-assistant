{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cb4c94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from utils_emotiontraining import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bcfc88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88ed6af86604317a3fdf6170f7fb57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d839d37b297414d8f685c1729e9b19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/3.00M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec9e1493536403382f4e8f7b8195c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/344k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99ddabca5bf47369f5d04d86f99c82b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/348k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a736678588974dce9a48e82d94787ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/46536 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097fbbc42a3b4ce49695ae21df728e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5427 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22dbd7309e8640e5a652c2b19b0bf5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/5426 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = TFAutoModel.from_pretrained(\"distilroberta-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilroberta-base\")\n",
    "emotion_dataset = load_dataset(\"jellyshroom/go_emotions_augmented\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa5c1b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = emotion_dataset['train'].select(range(20000))\n",
    "small_test_dataset = emotion_dataset['test'].select(range(1000))\n",
    "small_validation_dataset = emotion_dataset['validation'].select(range(1000))\n",
    "\n",
    "small_emotion_dataset = {\n",
    "    'train': small_train_dataset,\n",
    "    'test': small_test_dataset,\n",
    "    'validation': small_validation_dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efe6e794",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_id2label = {\n",
    "    0: 'admiration',\n",
    "    1: 'amusement',\n",
    "    2: 'anger',\n",
    "    3: 'annoyance',\n",
    "    4: 'approval',\n",
    "    5: 'caring',\n",
    "    6: 'confusion',\n",
    "    7: 'curiosity',\n",
    "    8: 'desire',\n",
    "    9: 'disappointment',\n",
    "    10: 'disapproval',\n",
    "    11: 'disgust',\n",
    "    12: 'embarrassment',\n",
    "    13: 'excitement',\n",
    "    14: 'fear',\n",
    "    15: 'gratitude',\n",
    "    16: 'grief',\n",
    "    17: 'joy',\n",
    "    18: 'love',\n",
    "    19: 'nervousness',\n",
    "    20: 'optimism',\n",
    "    21: 'pride',\n",
    "    22: 'realization',\n",
    "    23: 'relief',\n",
    "    24: 'remorse',\n",
    "    25: 'sadness',\n",
    "    26: 'surprise',\n",
    "    27: 'neutral'\n",
    "}\n",
    "\n",
    "emotions_label2id = {v: k for k, v in emotions_id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d906f8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a0c2976f0843249abb294ad237ad43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb631b56c84e4d88a82133ea44e89285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd52f172159f45268cb9d40a9ec63390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'labels', 'id', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 20000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True, return_tensors='tf')\n",
    "\n",
    "# Tokenize the small dataset\n",
    "small_emotions_encoded = {}\n",
    "small_emotions_encoded['train'] = small_emotion_dataset['train'].map(tokenize, batched=True, batch_size=None)\n",
    "small_emotions_encoded['test'] = small_emotion_dataset['test'].map(tokenize, batched=True, batch_size=None)\n",
    "small_emotions_encoded['validation'] = small_emotion_dataset['validation'].map(tokenize, batched=True, batch_size=None)\n",
    "\n",
    "print(small_emotions_encoded['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f6d48f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23eb712952274c7cacfdb8003c9e8497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b670fb955948859d2b0f413aaf1c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c155a4a99ee54b25a548b62c4a356401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing existing columns: ['labels']\n",
      "Renaming 'multi_hot_labels' to 'labels'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "\n",
    "NUM_CLASSES = 28  # Define the number of classes (matches emotions_id2label)\n",
    "\n",
    "def create_multi_hot_labels(example):\n",
    "    \"\"\"Convert the list of labels into a multi-hot encoded vector.\"\"\"\n",
    "    multi_hot_label = np.zeros(NUM_CLASSES, dtype=np.float32)\n",
    "    if 'labels' in example and isinstance(example['labels'], list) and len(example['labels']) > 0:\n",
    "        for label_id in example['labels']:\n",
    "            if isinstance(label_id, int) and 0 <= label_id < NUM_CLASSES:\n",
    "                multi_hot_label[label_id] = 1.0\n",
    "    example['multi_hot_labels'] = multi_hot_label\n",
    "    return example\n",
    "\n",
    "# Apply the conversion to add the new multi-hot label column\n",
    "small_emotions_encoded['train'] = small_emotions_encoded['train'].map(create_multi_hot_labels)\n",
    "small_emotions_encoded['test'] = small_emotions_encoded['test'].map(create_multi_hot_labels)\n",
    "small_emotions_encoded['validation'] = small_emotions_encoded['validation'].map(create_multi_hot_labels)\n",
    "\n",
    "# Remove the original 'labels' column and any leftover 'label_int'\n",
    "columns_to_remove = [col for col in ['label_int', 'labels'] if col in small_emotions_encoded['train'].features]\n",
    "if columns_to_remove:\n",
    "    print(f\"Removing existing columns: {columns_to_remove}\")\n",
    "    small_emotions_encoded['train'] = small_emotions_encoded['train'].remove_columns(columns_to_remove)\n",
    "    small_emotions_encoded['test'] = small_emotions_encoded['test'].remove_columns(columns_to_remove)\n",
    "    if 'validation' in small_emotions_encoded:\n",
    "        small_emotions_encoded['validation'] = small_emotions_encoded['validation'].remove_columns(columns_to_remove) # Added for validation set\n",
    "\n",
    "# Rename the new column 'multi_hot_labels' to 'labels'\n",
    "if 'multi_hot_labels' in small_emotions_encoded['train'].features:\n",
    "    print(\"Renaming 'multi_hot_labels' to 'labels'\")\n",
    "    small_emotions_encoded['train'] = small_emotions_encoded['train'].rename_column('multi_hot_labels', 'labels')\n",
    "if 'multi_hot_labels' in small_emotions_encoded['test'].features:\n",
    "    small_emotions_encoded['test'] = small_emotions_encoded['test'].rename_column('multi_hot_labels', 'labels')\n",
    "if 'validation' in small_emotions_encoded and 'multi_hot_labels' in small_emotions_encoded['validation'].features:\n",
    "    small_emotions_encoded['validation'] = small_emotions_encoded['validation'].rename_column('multi_hot_labels', 'labels') # Added for validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd236d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating sample weights...\n",
      "Sample weights calculated.\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating sample weights...\")\n",
    "# Get all multi-hot labels from the training set as a NumPy array\n",
    "train_labels_np = np.array(small_emotions_encoded['train']['labels'])\n",
    "# Count frequency of each label (column-wise sum)\n",
    "label_counts = np.sum(train_labels_np, axis=0)\n",
    "total_samples = len(train_labels_np)\n",
    "\n",
    "# Calculate weight for each class (inverse frequency, smoothed)\n",
    "class_weights_calc = {}\n",
    "for i in range(NUM_CLASSES):\n",
    "    count = label_counts[i] if label_counts[i] > 0 else 1\n",
    "    class_weights_calc[i] = total_samples / (NUM_CLASSES * count)\n",
    "\n",
    "# Calculate weight for each sample: max weight of its positive labels\n",
    "sample_weights_np = np.zeros(total_samples, dtype=np.float32)\n",
    "for i in range(total_samples):\n",
    "    sample_label_indices = np.where(train_labels_np[i] == 1.0)[0]\n",
    "    if len(sample_label_indices) > 0:\n",
    "        sample_weights_np[i] = max(class_weights_calc[idx] for idx in sample_label_indices)\n",
    "    else:\n",
    "        # Assign a default weight (e.g., 1.0 or average) for samples with no positive labels\n",
    "        sample_weights_np[i] = 1.0\n",
    "print(\"Sample weights calculated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c44f0d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting dataset format to TensorFlow\n"
     ]
    }
   ],
   "source": [
    "# Set format to tensorflow\n",
    "feature_cols = [\"input_ids\", \"attention_mask\"]\n",
    "label_col = \"labels\"\n",
    "cols_to_set_format = feature_cols + [label_col]\n",
    "\n",
    "actual_train_cols = list(small_emotions_encoded['train'].features)\n",
    "actual_test_cols = list(small_emotions_encoded['test'].features)\n",
    "actual_validation_cols = list(small_emotions_encoded['validation'].features)\n",
    "final_train_cols = [col for col in cols_to_set_format if col in actual_train_cols]\n",
    "final_test_cols = [col for col in cols_to_set_format if col in actual_test_cols]\n",
    "final_validation_cols = [col for col in cols_to_set_format if col in actual_validation_cols]\n",
    "\n",
    "if all(col in final_train_cols for col in cols_to_set_format) and \\\n",
    "   all(col in final_test_cols for col in cols_to_set_format) and \\\n",
    "   all(col in final_validation_cols for col in cols_to_set_format):\n",
    "    print(\"Setting dataset format to TensorFlow\")\n",
    "    # Don't set format yet, extract numpy arrays first, then create dataset\n",
    "else:\n",
    "     raise ValueError(f\"Error: Could not find all necessary columns. Train has: {actual_train_cols}, Test has: {actual_test_cols}. Needed: {cols_to_set_format}\")\n",
    "\n",
    "\n",
    "# Extract features and labels as numpy arrays before creating dataset\n",
    "train_features_np = {col: np.array(small_emotions_encoded['train'][col]) for col in feature_cols}\n",
    "train_labels_np = np.array(small_emotions_encoded['train']['labels']) # Already have this from weight calc\n",
    "\n",
    "test_features_np = {col: np.array(small_emotions_encoded['test'][col]) for col in feature_cols}\n",
    "test_labels_np = np.array(small_emotions_encoded['test']['labels'])\n",
    "\n",
    "validation_features_np = {col: np.array(small_emotions_encoded['validation'][col]) for col in feature_cols}\n",
    "validation_labels_np = np.array(small_emotions_encoded['validation']['labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f6e61c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tf.data.Dataset objects with sample weights...\n",
      "Datasets created successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create TensorFlow datasets\n",
    "BATCH_SIZE = 32 # Keep batch size reasonable\n",
    "\n",
    "print(\"Creating tf.data.Dataset objects with sample weights...\")\n",
    "# Modify train_dataset to yield (features, labels, sample_weights)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_features_np, train_labels_np, sample_weights_np)\n",
    ")\n",
    "train_dataset = train_dataset.shuffle(len(sample_weights_np)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE) # Add prefetch\n",
    "\n",
    "# Test dataset remains (features, labels)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (test_features_np, test_labels_np)\n",
    ")\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE) # Add prefetch\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (validation_features_np, validation_labels_np)\n",
    ")\n",
    "validation_dataset = validation_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE) # Add prefetch\n",
    "\n",
    "\n",
    "print(\"Datasets created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e067bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTForClassification(tf.keras.Model):\n",
    "    def __init__(self, bert_model, num_classes):\n",
    "        super().__init__()\n",
    "        self.bert = bert_model\n",
    "        self.num_classes = num_classes # STORE num_classes\n",
    "        # Change activation to 'sigmoid' for multi-label classification\n",
    "        self.fc = tf.keras.layers.Dense(num_classes, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Make sure we handle the case when inputs is a dictionary\n",
    "        outputs = self.bert(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            return_dict=True\n",
    "        )\n",
    "        pooled_output = outputs.pooler_output\n",
    "        return self.fc(pooled_output)\n",
    "\n",
    "    # ADD THIS METHOD\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_classes\": self.num_classes\n",
    "            # bert_model is not included as it's complex and loaded separately\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce5b9f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define NUM_CLASSES if not defined globally earlier\n",
    "try:\n",
    "    NUM_CLASSES\n",
    "except NameError:\n",
    "    NUM_CLASSES = 28 # Set default if run out of order\n",
    "\n",
    "# Create a shared emotion prediction function for multi-label output\n",
    "def predict_emotion(text, model, threshold=0.5):\n",
    "    \"\"\"Predict multiple emotions for a given text using the provided model and threshold\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors='tf', padding=True, truncation=True)\n",
    "    predictions = model(inputs) # Shape: (1, NUM_CLASSES)\n",
    "\n",
    "    # --- Add this line temporarily ---\n",
    "    print(f\"Raw probabilities for '{text}': {predictions[0].numpy()}\")\n",
    "    # --- End of added line ---\n",
    "\n",
    "    predicted_labels_indices = tf.where(predictions[0] > threshold).numpy().flatten()\n",
    "    predicted_emotions = []\n",
    "    confidences = []\n",
    "    if len(predicted_labels_indices) > 0:\n",
    "        for index in predicted_labels_indices:\n",
    "            predicted_emotions.append(emotions_id2label[index])\n",
    "            confidences.append(float(predictions[0][index]))\n",
    "    else:\n",
    "        # Optional: If no label passes threshold, predict the highest one or 'neutral'\n",
    "        highest_prob_index = tf.argmax(predictions, axis=1).numpy()[0]\n",
    "        predicted_emotions.append(emotions_id2label[highest_prob_index])\n",
    "        confidences.append(float(predictions[0][highest_prob_index]))\n",
    "\n",
    "\n",
    "    return {\n",
    "        'text': text,\n",
    "        'emotions': predicted_emotions,\n",
    "        'confidences': confidences\n",
    "    }\n",
    "\n",
    "# Define test texts to use for both untrained and trained models\n",
    "test_texts = [\n",
    "    \"I'm so happy today!\",\n",
    "    \"This makes me really angry.\",\n",
    "    \"I'm feeling very sad and disappointed.\",\n",
    "    \"That's really interesting, tell me more.\",\n",
    "    \"I am both excited and nervous about the presentation.\", # Example with multiple emotions\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87469b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions with UNTRAINED model (random weights - multi-label):\n",
      "-------------------------------------------------------------\n",
      "Raw probabilities for 'I'm so happy today!': [0.3647775  0.46604145 0.71257216 0.6748999  0.5231001  0.4923539\n",
      " 0.81130844 0.22087218 0.33193052 0.32434133 0.2523739  0.36111632\n",
      " 0.5680941  0.57176626 0.3669782  0.4474013  0.27805743 0.5727703\n",
      " 0.90865403 0.24848849 0.74004817 0.5476425  0.59768933 0.4063118\n",
      " 0.29717106 0.529662   0.4651278  0.23796488]\n",
      "Text: I'm so happy today!\n",
      "Predicted emotions: ['anger', 'annoyance', 'approval', 'confusion', 'embarrassment', 'excitement', 'joy', 'love', 'optimism', 'pride', 'realization', 'sadness']\n",
      "Confidences: [('anger', 0.7125721573829651), ('annoyance', 0.6748998761177063), ('approval', 0.5231000781059265), ('confusion', 0.8113084435462952), ('embarrassment', 0.5680940747261047), ('excitement', 0.5717662572860718), ('joy', 0.5727702975273132), ('love', 0.9086540341377258), ('optimism', 0.7400481700897217), ('pride', 0.5476425290107727), ('realization', 0.5976893305778503), ('sadness', 0.529662013053894)]\n",
      "\n",
      "Raw probabilities for 'This makes me really angry.': [0.30946496 0.5098582  0.79231286 0.63707054 0.37821564 0.37506184\n",
      " 0.85168123 0.27562937 0.3985127  0.3112764  0.30717254 0.6096062\n",
      " 0.31821856 0.59820026 0.28520885 0.456652   0.2655613  0.60708773\n",
      " 0.9472032  0.35628012 0.6766262  0.6134323  0.543749   0.4413022\n",
      " 0.36846986 0.6683366  0.4507269  0.26726264]\n",
      "Text: This makes me really angry.\n",
      "Predicted emotions: ['amusement', 'anger', 'annoyance', 'confusion', 'disgust', 'excitement', 'joy', 'love', 'optimism', 'pride', 'realization', 'sadness']\n",
      "Confidences: [('amusement', 0.5098581910133362), ('anger', 0.7923128604888916), ('annoyance', 0.6370705366134644), ('confusion', 0.8516812324523926), ('disgust', 0.6096062064170837), ('excitement', 0.598200261592865), ('joy', 0.6070877313613892), ('love', 0.9472032189369202), ('optimism', 0.6766262054443359), ('pride', 0.6134322881698608), ('realization', 0.5437489748001099), ('sadness', 0.6683365702629089)]\n",
      "\n",
      "Raw probabilities for 'I'm feeling very sad and disappointed.': [0.2208456  0.43982872 0.7917236  0.6506276  0.59941155 0.48301712\n",
      " 0.7931403  0.30837095 0.48695236 0.19161011 0.20696405 0.58425564\n",
      " 0.4844951  0.5360004  0.32699364 0.56159276 0.22661434 0.6533275\n",
      " 0.93004096 0.4020089  0.7663645  0.647437   0.5181547  0.33579516\n",
      " 0.35942972 0.62220645 0.49187317 0.24161483]\n",
      "Text: I'm feeling very sad and disappointed.\n",
      "Predicted emotions: ['anger', 'annoyance', 'approval', 'confusion', 'disgust', 'excitement', 'gratitude', 'joy', 'love', 'optimism', 'pride', 'realization', 'sadness']\n",
      "Confidences: [('anger', 0.7917236089706421), ('annoyance', 0.650627613067627), ('approval', 0.5994115471839905), ('confusion', 0.7931402921676636), ('disgust', 0.5842556357383728), ('excitement', 0.5360003709793091), ('gratitude', 0.5615927577018738), ('joy', 0.6533275246620178), ('love', 0.9300409555435181), ('optimism', 0.7663645148277283), ('pride', 0.6474369764328003), ('realization', 0.5181546807289124), ('sadness', 0.622206449508667)]\n",
      "\n",
      "Raw probabilities for 'That's really interesting, tell me more.': [0.3872001  0.39747974 0.8190166  0.7824984  0.4126372  0.5389252\n",
      " 0.752855   0.23712441 0.5742965  0.44073656 0.43668908 0.47929275\n",
      " 0.52314997 0.7110671  0.351178   0.44407886 0.17251198 0.7159028\n",
      " 0.9057     0.20503472 0.7210237  0.63589793 0.5263061  0.46338567\n",
      " 0.37465733 0.44763163 0.62193155 0.2103447 ]\n",
      "Text: That's really interesting, tell me more.\n",
      "Predicted emotions: ['anger', 'annoyance', 'caring', 'confusion', 'desire', 'embarrassment', 'excitement', 'joy', 'love', 'optimism', 'pride', 'realization', 'surprise']\n",
      "Confidences: [('anger', 0.8190165758132935), ('annoyance', 0.7824984192848206), ('caring', 0.5389251708984375), ('confusion', 0.7528550028800964), ('desire', 0.5742964744567871), ('embarrassment', 0.5231499671936035), ('excitement', 0.7110670804977417), ('joy', 0.7159028053283691), ('love', 0.9057000279426575), ('optimism', 0.721023678779602), ('pride', 0.6358979344367981), ('realization', 0.5263060927391052), ('surprise', 0.6219315528869629)]\n",
      "\n",
      "Raw probabilities for 'I am both excited and nervous about the presentation.': [0.44398844 0.36686435 0.81718546 0.6975254  0.3548482  0.5548987\n",
      " 0.76244646 0.18444028 0.49720454 0.37162116 0.23140351 0.662273\n",
      " 0.4459941  0.436713   0.2759324  0.52846    0.20862041 0.7491824\n",
      " 0.921823   0.25911307 0.6602973  0.5740591  0.6014211  0.5142351\n",
      " 0.19801247 0.4317803  0.38281742 0.21433903]\n",
      "Text: I am both excited and nervous about the presentation.\n",
      "Predicted emotions: ['anger', 'annoyance', 'caring', 'confusion', 'disgust', 'gratitude', 'joy', 'love', 'optimism', 'pride', 'realization', 'relief']\n",
      "Confidences: [('anger', 0.8171854615211487), ('annoyance', 0.6975253820419312), ('caring', 0.5548986792564392), ('confusion', 0.7624464631080627), ('disgust', 0.6622729897499084), ('gratitude', 0.5284600257873535), ('joy', 0.749182403087616), ('love', 0.9218230247497559), ('optimism', 0.6602972745895386), ('pride', 0.5740591287612915), ('realization', 0.6014211177825928), ('relief', 0.5142350792884827)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an untrained model for baseline comparison\n",
    "# Ensure the base model 'model' is loaded correctly from cell 2\n",
    "untrained_classifier = BERTForClassification(model, num_classes=NUM_CLASSES)\n",
    "\n",
    "# Compile the model for multi-label classification\n",
    "untrained_classifier.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=2e-5),\n",
    "    # Use BinaryCrossentropy for multi-label with sigmoid activation\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    # Use BinaryAccuracy for multi-label evaluation\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "print(\"Predictions with UNTRAINED model (random weights - multi-label):\")\n",
    "print(\"-------------------------------------------------------------\")\n",
    "\n",
    "for text in test_texts:\n",
    "    result = predict_emotion(text, untrained_classifier, threshold=0.5)\n",
    "    print(f\"Text: {result['text']}\")\n",
    "    print(f\"Predicted emotions: {result['emotions']}\")\n",
    "    # Zip confidences with emotions for clarity\n",
    "    emotion_confidence_pairs = list(zip(result['emotions'], result['confidences']))\n",
    "    print(f\"Confidences: {emotion_confidence_pairs}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d127d7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.AdamW` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.AdamW`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model with AUC, Precision, Recall...\n",
      "Model compiled.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    NUM_CLASSES\n",
    "except NameError:\n",
    "    NUM_CLASSES = 28\n",
    "\n",
    "# Define the model - ensure 'model' (the base BERT model) is loaded\n",
    "classifier = BERTForClassification(model, num_classes=NUM_CLASSES)\n",
    "\n",
    "# Compile the model for multi-label classification with more metrics\n",
    "print(\"Compiling model with AUC, Precision, Recall...\")\n",
    "classifier.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=2e-5), # Consider trying AdamW later\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.AUC(multi_label=True, name='auc'),\n",
    "        tf.keras.metrics.Precision(name='precision'), # How many selected items are relevant?\n",
    "        tf.keras.metrics.Recall(name='recall') # How many relevant items are selected?\n",
    "        ]\n",
    ")\n",
    "print(\"Model compiled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9df6074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting multi-label model training with sample weights...\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 3146s 5s/step - loss: 0.1398 - accuracy: 0.9568 - auc: 0.8232 - precision: 0.4528 - recall: 0.1283 - val_loss: 0.1168 - val_accuracy: 0.9632 - val_auc: 0.8921 - val_precision: 0.6888 - val_recall: 0.2659\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 3169s 5s/step - loss: 0.0976 - accuracy: 0.9636 - auc: 0.9131 - precision: 0.6691 - recall: 0.2684 - val_loss: 0.1080 - val_accuracy: 0.9622 - val_auc: 0.8998 - val_precision: 0.6287 - val_recall: 0.3016\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 3159s 5s/step - loss: 0.0844 - accuracy: 0.9646 - auc: 0.9334 - precision: 0.6525 - recall: 0.3392 - val_loss: 0.1055 - val_accuracy: 0.9620 - val_auc: 0.9078 - val_precision: 0.6059 - val_recall: 0.3389\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 3036s 5s/step - loss: 0.0754 - accuracy: 0.9657 - auc: 0.9463 - precision: 0.6532 - recall: 0.3946 - val_loss: 0.1052 - val_accuracy: 0.9619 - val_auc: 0.9084 - val_precision: 0.5858 - val_recall: 0.3960\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 3344s 5s/step - loss: 0.0677 - accuracy: 0.9670 - auc: 0.9546 - precision: 0.6634 - recall: 0.4365 - val_loss: 0.1059 - val_accuracy: 0.9618 - val_auc: 0.9136 - val_precision: 0.5752 - val_recall: 0.4341\n",
      "Training finished.\n",
      "Evaluating model on test set...\n",
      "32/32 [==============================] - 16s 447ms/step - loss: 0.1022 - accuracy: 0.9621 - auc: 0.9239 - precision: 0.5551 - recall: 0.4226\n",
      "\n",
      "Test Set Evaluation Results:\n",
      "- loss: 0.1022\n",
      "- accuracy: 0.9621\n",
      "- auc: 0.9239\n",
      "- precision: 0.5551\n",
      "- recall: 0.4226\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Starting multi-label model training with sample weights...\")\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=3, mode='max', restore_best_weights=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint('best_emotion_model.keras', save_best_only=True, monitor='val_auc', mode='max')\n",
    "]\n",
    "\n",
    "history = classifier.fit(\n",
    "    train_dataset,\n",
    "    epochs=5,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks # Uncomment to use callbacks\n",
    ")\n",
    "print(\"Training finished.\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(\"Evaluating model on test set...\")\n",
    "results = classifier.evaluate(test_dataset, verbose=1) # Use verbose=1 to see progress\n",
    "\n",
    "# Print evaluation results dynamically based on compiled metrics\n",
    "print(\"\\nTest Set Evaluation Results:\")\n",
    "for name, value in zip(classifier.metrics_names, results):\n",
    "    print(f\"- {name}: {value:.4f}\")\n",
    "\n",
    "# test_loss = results[classifier.metrics_names.index('loss')]\n",
    "# test_auc = results[classifier.metrics_names.index('auc')]\n",
    "# print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "# print(f\"Test AUC: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f61dbca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions with TRAINED multi-label model:\n",
      "----------------------------------------\n",
      "Loading best model weights from checkpoint...\n",
      "Raw probabilities for 'I'm so happy today!': [3.5804652e-02 6.7219036e-03 3.5327272e-03 4.2225751e-03 2.2938062e-02\n",
      " 2.1542782e-02 1.8839212e-03 4.4516129e-03 4.6389336e-03 2.3737701e-03\n",
      " 9.3714846e-04 1.1744318e-03 3.6886306e-03 8.9674823e-02 2.7164354e-03\n",
      " 2.1942558e-02 8.9404261e-04 9.5895094e-01 3.8458385e-02 2.9750334e-03\n",
      " 8.6716171e-03 3.1830974e-02 1.1759102e-02 7.2076959e-03 3.7947532e-03\n",
      " 1.0251633e-02 2.5655765e-03 6.0006138e-03]\n",
      "Text: I'm so happy today!\n",
      "Predicted emotions: ['joy']\n",
      "Confidences: [('joy', 0.958950936794281)]\n",
      "\n",
      "Raw probabilities for 'This makes me really angry.': [0.0045552  0.01158904 0.9307607  0.18818492 0.00901619 0.00386939\n",
      " 0.00210112 0.00174721 0.00395207 0.01632867 0.0182901  0.07202452\n",
      " 0.0048206  0.00815627 0.0109376  0.01113673 0.0043633  0.00679844\n",
      " 0.00830816 0.00545055 0.00529313 0.02591576 0.00787402 0.01033634\n",
      " 0.01601159 0.06534464 0.00151269 0.01228255]\n",
      "Text: This makes me really angry.\n",
      "Predicted emotions: ['anger']\n",
      "Confidences: [('anger', 0.9307606816291809)]\n",
      "\n",
      "Raw probabilities for 'I'm feeling very sad and disappointed.': [0.00692218 0.0074403  0.01831827 0.03195401 0.00311894 0.00657425\n",
      " 0.00370335 0.00228662 0.00706116 0.36695838 0.00739738 0.01540056\n",
      " 0.00349266 0.00393722 0.00770722 0.00438872 0.00339057 0.01441938\n",
      " 0.00770459 0.0093276  0.00721575 0.00471055 0.00568909 0.00940593\n",
      " 0.01347096 0.96940005 0.00439415 0.00667937]\n",
      "Text: I'm feeling very sad and disappointed.\n",
      "Predicted emotions: ['disappointment', 'sadness']\n",
      "Confidences: [('disappointment', 0.3669583797454834), ('sadness', 0.9694000482559204)]\n",
      "\n",
      "Raw probabilities for 'That's really interesting, tell me more.': [0.49551183 0.00931254 0.00245684 0.00573302 0.11254345 0.00396226\n",
      " 0.00893273 0.39112338 0.00530446 0.00410705 0.00373566 0.00232179\n",
      " 0.00086584 0.78839535 0.00253985 0.00929369 0.0008488  0.02247521\n",
      " 0.01239915 0.00123113 0.0152177  0.00421847 0.00893693 0.00214573\n",
      " 0.00290071 0.00206129 0.02813537 0.01482632]\n",
      "Text: That's really interesting, tell me more.\n",
      "Predicted emotions: ['admiration', 'curiosity', 'excitement']\n",
      "Confidences: [('admiration', 0.49551182985305786), ('curiosity', 0.39112338423728943), ('excitement', 0.788395345211029)]\n",
      "\n",
      "Raw probabilities for 'I am both excited and nervous about the presentation.': [0.03242409 0.00827493 0.00607139 0.00354569 0.01305448 0.00513253\n",
      " 0.00280496 0.01493806 0.00169727 0.00546928 0.00609677 0.00356888\n",
      " 0.00421593 0.45012072 0.03013832 0.00412982 0.00194403 0.04061623\n",
      " 0.02452317 0.67436695 0.00625304 0.01296006 0.00579741 0.00749079\n",
      " 0.00426568 0.007108   0.00165895 0.00716224]\n",
      "Text: I am both excited and nervous about the presentation.\n",
      "Predicted emotions: ['excitement', 'nervousness']\n",
      "Confidences: [('excitement', 0.4501207172870636), ('nervousness', 0.6743669509887695)]\n",
      "\n",
      "Raw probabilities for 'My hands were shaking as I opened the letter, unsure what to expect.': [0.0042625  0.00119547 0.00348068 0.0054944  0.00634718 0.00693825\n",
      " 0.0357044  0.01338243 0.00225229 0.01437693 0.01419455 0.01159769\n",
      " 0.01335576 0.00225554 0.59123045 0.00586107 0.00335088 0.00292679\n",
      " 0.00685994 0.9157782  0.00324313 0.00218759 0.02513889 0.00163956\n",
      " 0.00114355 0.04794304 0.01840492 0.00692651]\n",
      "Text: My hands were shaking as I opened the letter, unsure what to expect.\n",
      "Predicted emotions: ['fear', 'nervousness']\n",
      "Confidences: [('fear', 0.5912304520606995), ('nervousness', 0.9157782196998596)]\n",
      "\n",
      "Raw probabilities for 'After the argument, the silence in the car was deafening and heavy.': [0.00156641 0.00205664 0.0946234  0.31837106 0.01106797 0.00155339\n",
      " 0.00235426 0.00121885 0.00093    0.55386066 0.06313477 0.05428016\n",
      " 0.0140076  0.00221597 0.00573459 0.00129741 0.00244267 0.00232209\n",
      " 0.00058545 0.00164975 0.00339178 0.00110766 0.0391361  0.01310494\n",
      " 0.00274253 0.0748376  0.00694101 0.16091672]\n",
      "Text: After the argument, the silence in the car was deafening and heavy.\n",
      "Predicted emotions: ['annoyance', 'disappointment']\n",
      "Confidences: [('annoyance', 0.318371057510376), ('disappointment', 0.5538606643676758)]\n",
      "\n",
      "Raw probabilities for 'Watching the sunset reminded me of our last trip together - a bittersweet memory.': [3.4514472e-02 2.3093061e-03 5.0768646e-04 1.2053638e-03 1.9875107e-02\n",
      " 4.3719518e-03 1.0215138e-03 2.3977365e-03 5.3361505e-03 2.7810916e-02\n",
      " 2.0787083e-03 9.1280683e-04 3.7913332e-03 8.6406013e-03 1.1985900e-02\n",
      " 9.4873790e-04 4.5631821e-03 5.0350044e-02 7.6134376e-02 6.0263883e-02\n",
      " 5.1343441e-03 5.7889111e-03 9.5754988e-02 5.2178726e-03 4.5265253e-03\n",
      " 5.2589655e-01 8.8053569e-03 2.4771841e-02]\n",
      "Text: Watching the sunset reminded me of our last trip together - a bittersweet memory.\n",
      "Predicted emotions: ['sadness']\n",
      "Confidences: [('sadness', 0.5258965492248535)]\n",
      "\n",
      "Raw probabilities for 'I'm relieved the project is finally over, but also a bit anxious about what comes next.': [0.00553876 0.00565474 0.00213286 0.00267141 0.02888783 0.01249907\n",
      " 0.00439613 0.00477901 0.00153702 0.00552593 0.005643   0.00394462\n",
      " 0.00172744 0.00684183 0.00544246 0.0149553  0.00278535 0.09426981\n",
      " 0.01717789 0.47311077 0.00797537 0.00505316 0.00968605 0.6267952\n",
      " 0.00095604 0.00380128 0.00343336 0.00335584]\n",
      "Text: I'm relieved the project is finally over, but also a bit anxious about what comes next.\n",
      "Predicted emotions: ['nervousness', 'relief']\n",
      "Confidences: [('nervousness', 0.47311076521873474), ('relief', 0.6267951726913452)]\n",
      "\n",
      "Raw probabilities for 'Oh great, another 'urgent' all-hands meeting scheduled for 5 PM on a Friday. Just perfect.': [0.9042999  0.00234416 0.00162998 0.0028269  0.10190682 0.00195456\n",
      " 0.00277052 0.00880299 0.00206886 0.00840379 0.0023961  0.00455909\n",
      " 0.00316555 0.44691548 0.00362324 0.01327853 0.00140387 0.12025627\n",
      " 0.00304417 0.00166761 0.00408127 0.01153369 0.00560388 0.11926938\n",
      " 0.00400547 0.00314396 0.02636554 0.00661814]\n",
      "Text: Oh great, another 'urgent' all-hands meeting scheduled for 5 PM on a Friday. Just perfect.\n",
      "Predicted emotions: ['admiration', 'excitement']\n",
      "Confidences: [('admiration', 0.9042999148368835), ('excitement', 0.44691547751426697)]\n",
      "\n",
      "Raw probabilities for 'Getting a flat tire miles from anywhere on the way to the most important interview of my life was exactly the kind of luck I needed.': [0.05631203 0.00255124 0.00324851 0.01345694 0.34948578 0.0177472\n",
      " 0.00535734 0.00248457 0.06750574 0.05240845 0.05610984 0.00573078\n",
      " 0.00647652 0.00226237 0.00521356 0.02530411 0.00060749 0.00276981\n",
      " 0.00307069 0.00261216 0.44980687 0.00260791 0.21453422 0.04136289\n",
      " 0.00141885 0.00231046 0.01499487 0.07064754]\n",
      "Text: Getting a flat tire miles from anywhere on the way to the most important interview of my life was exactly the kind of luck I needed.\n",
      "Predicted emotions: ['approval', 'optimism', 'realization']\n",
      "Confidences: [('approval', 0.3494857847690582), ('optimism', 0.4498068690299988), ('realization', 0.2145342230796814)]\n",
      "\n",
      "Raw probabilities for 'He delivered the bad news with a completely straight face, leaving us all reeling.': [0.01350709 0.00156794 0.04993204 0.12928523 0.00934597 0.00317685\n",
      " 0.00122894 0.00090021 0.00073206 0.60933334 0.02036952 0.03320296\n",
      " 0.00579561 0.00681929 0.00813912 0.00149175 0.00157631 0.00594053\n",
      " 0.00078154 0.00162322 0.00499965 0.00322448 0.00902661 0.00688515\n",
      " 0.00800849 0.33947325 0.01180622 0.07640308]\n",
      "Text: He delivered the bad news with a completely straight face, leaving us all reeling.\n",
      "Predicted emotions: ['disappointment', 'sadness']\n",
      "Confidences: [('disappointment', 0.609333336353302), ('sadness', 0.33947324752807617)]\n",
      "\n",
      "Raw probabilities for 'Well, that certainly was an experience I won't forget anytime soon.': [3.7092289e-01 4.2731976e-03 4.9728429e-04 2.1650691e-03 6.6959572e-01\n",
      " 1.6339391e-03 3.2797416e-03 2.5970868e-03 1.4155401e-02 3.4917846e-02\n",
      " 1.5987618e-02 1.3558249e-03 1.0949663e-03 2.1156088e-02 2.9001632e-03\n",
      " 8.1513291e-03 1.3756145e-03 1.4123199e-02 4.4179037e-03 1.9255198e-03\n",
      " 1.5009403e-01 3.2780354e-03 3.9885005e-01 1.8715698e-02 5.5556041e-03\n",
      " 3.4466656e-03 1.0277928e-02 5.6526236e-02]\n",
      "Text: Well, that certainly was an experience I won't forget anytime soon.\n",
      "Predicted emotions: ['admiration', 'approval', 'realization']\n",
      "Confidences: [('admiration', 0.37092289328575134), ('approval', 0.6695957183837891), ('realization', 0.39885005354881287)]\n",
      "\n",
      "Raw probabilities for 'I wouldn't say I'm *thrilled* about the sudden change in plans, but I suppose I can adapt if necessary.': [1.6414007e-02 1.1530538e-02 6.1661280e-03 3.3604585e-02 5.0602847e-01\n",
      " 4.9850196e-03 1.6274514e-02 5.4735658e-03 2.7088944e-02 8.6260580e-02\n",
      " 5.4684464e-02 6.9409730e-03 1.6444841e-03 3.7281020e-03 3.5692286e-03\n",
      " 3.9610416e-03 4.6820071e-04 2.5489654e-03 1.2498333e-03 9.5129078e-03\n",
      " 8.3760822e-01 6.2783407e-03 2.8034875e-01 3.9417697e-03 1.4873487e-03\n",
      " 4.6015056e-03 5.7373089e-03 1.9176152e-01]\n",
      "Text: I wouldn't say I'm *thrilled* about the sudden change in plans, but I suppose I can adapt if necessary.\n",
      "Predicted emotions: ['approval', 'optimism', 'realization']\n",
      "Confidences: [('approval', 0.5060284733772278), ('optimism', 0.8376082181930542), ('realization', 0.2803487479686737)]\n",
      "\n",
      "Raw probabilities for 'Despite the initial burst of optimism, realizing the sheer amount of unexpected work ahead filled me with a quiet sense of dread.': [0.02149222 0.00463124 0.0053424  0.00820167 0.01929399 0.00235648\n",
      " 0.00101829 0.0009914  0.00441804 0.03095214 0.0085268  0.00412313\n",
      " 0.0152256  0.00571428 0.64444685 0.00579936 0.00160968 0.0086897\n",
      " 0.00354556 0.06844445 0.00498018 0.00322605 0.33661515 0.00505486\n",
      " 0.00451688 0.0496107  0.01947118 0.01072411]\n",
      "Text: Despite the initial burst of optimism, realizing the sheer amount of unexpected work ahead filled me with a quiet sense of dread.\n",
      "Predicted emotions: ['fear', 'realization']\n",
      "Confidences: [('fear', 0.644446849822998), ('realization', 0.3366151452064514)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions with TRAINED multi-label model:\")\n",
    "print(\"----------------------------------------\")\n",
    "\n",
    "# Use the updated shared function with the trained model\n",
    "prediction_threshold = 0.2 # Adjust threshold as needed based on validation performance\n",
    "\n",
    "test_texts = TEST_TEXTS\n",
    "\n",
    "print(\"Loading best model weights from checkpoint...\")\n",
    "classifier.load_weights('best_emotion_model.keras')\n",
    "\n",
    "for text in test_texts:\n",
    "    result = predict_emotion(text, classifier, threshold=prediction_threshold)\n",
    "    print(f\"Text: {result['text']}\")\n",
    "    print(f\"Predicted emotions: {result['emotions']}\")\n",
    "    # Zip confidences with emotions for clarity\n",
    "    emotion_confidence_pairs = list(zip(result['emotions'], result['confidences']))\n",
    "    print(f\"Confidences: {emotion_confidence_pairs}\")\n",
    "    # print(f\"Confidences: {[f'{c:.4f}' for c in result['confidences']]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d42308a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'joy', 'score': 0.9998683929443359}, {'label': 'anger', 'score': 0.9998956918716431}, {'label': 'sadness', 'score': 0.9999432563781738}, {'label': 'neutral', 'score': 0.7713387608528137}, {'label': 'fear', 'score': 0.9935625791549683}, {'label': 'fear', 'score': 0.9996892213821411}, {'label': 'anger', 'score': 0.9703493714332581}, {'label': 'joy', 'score': 0.9454078674316406}, {'label': 'joy', 'score': 0.6393844485282898}, {'label': 'neutral', 'score': 0.7897074222564697}, {'label': 'sadness', 'score': 0.9980188608169556}, {'label': 'fear', 'score': 0.5129643082618713}, {'label': 'neutral', 'score': 0.9996825456619263}, {'label': 'joy', 'score': 0.9929666519165039}, {'label': 'fear', 'score': 0.9995587468147278}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model = 'borisn70/bert-43-multilabel-emotion-detection'\n",
    "tokenizer = 'borisn70/bert-43-multilabel-emotion-detection'\n",
    "\n",
    "# Create a pipeline for sentiment analysis\n",
    "nlp = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)\n",
    "\n",
    "testTexts = TEST_TEXTS\n",
    "result = nlp(testTexts)\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
